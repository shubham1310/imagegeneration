{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Implements SRGAN models: https://arxiv.org/abs/1609.04802\n",
    "TODO:\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def swish(x):\n",
    "    return x * F.sigmoid(x)\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, cnn, feature_layer=11):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.features = nn.Sequential(*list(cnn.features.children())[:(feature_layer+1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "\n",
    "class residualBlock(nn.Module):\n",
    "    def __init__(self, in_channels=64, k=3, n=64, s=1):\n",
    "        super(residualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, n, k, stride=s, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(n)\n",
    "        self.conv2 = nn.Conv2d(n, n, k, stride=s, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = swish(self.bn1(self.conv1(x)))\n",
    "        return self.bn2(self.conv2(y)) + x\n",
    "\n",
    "class upsampleBlock(nn.Module):\n",
    "    # Implements resize-convolution\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(upsampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1)\n",
    "        self.shuffler = nn.PixelShuffle(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return swish(self.shuffler(self.conv(x)))\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_residual_blocks, upsample_factor):\n",
    "        super(Generator, self).__init__()\n",
    "        self.n_residual_blocks = n_residual_blocks\n",
    "        self.upsample_factor = upsample_factor\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, 9, stride=1, padding=4)\n",
    "\n",
    "        for i in range(self.n_residual_blocks):\n",
    "            self.add_module('residual_block' + str(i+1), residualBlock())\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        for i in range(self.upsample_factor/2):\n",
    "            self.add_module('upsample' + str(i+1), upsampleBlock(64, 256))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 3, 9, stride=1, padding=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = swish(self.conv1(x))\n",
    "\n",
    "        y = x.clone()\n",
    "        for i in range(self.n_residual_blocks):\n",
    "            y = self.__getattr__('residual_block' + str(i+1))(y)\n",
    "\n",
    "        x = self.bn2(self.conv2(y)) + x\n",
    "\n",
    "        for i in range(self.upsample_factor/2):\n",
    "            x = self.__getattr__('upsample' + str(i+1))(x)\n",
    "\n",
    "        return self.conv3(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, stride=2, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        self.conv7 = nn.Conv2d(256, 512, 3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(512)\n",
    "        self.conv8 = nn.Conv2d(512, 512, 3, stride=2, padding=1)\n",
    "        self.conv8_bn = nn.BatchNorm2d(512)\n",
    "        self.conv9 = nn.Conv2d(512, 512, 3, stride=4, padding=0)\n",
    "        self.conv9_bn = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "\n",
    "        # Replaced original paper FC layers with FCN\n",
    "        # self.conv9 = nn.Conv2d(512, 1, 1, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = swish(self.conv1(x))\n",
    "\n",
    "        x = swish(self.bn2(self.conv2(x)))\n",
    "        x = swish(self.bn3(self.conv3(x)))\n",
    "        x = swish(self.bn4(self.conv4(x)))\n",
    "        x = swish(self.bn5(self.conv5(x)))\n",
    "        x = swish(self.bn6(self.conv6(x)))\n",
    "        x = swish(self.bn7(self.conv7(x)))\n",
    "        x = swish(self.conv8_bn(self.conv8(x)))\n",
    "        x = swish(self.conv9_bn(self.conv9(x)))\n",
    "\n",
    "        print(x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.size())\n",
    "        print(self.fc1(x).size())\n",
    "        x = F.elu(self.fc1(x))\n",
    "        print('uwuw')\n",
    "        return F.sigmoid(self.fc2(x))\n",
    "\n",
    "        # x = self.conv9(x)\n",
    "        # return F.sigmoid(F.avg_pool2d(x, x.size()[2:])).view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tensorboard_logger import configure, log_value\n",
    "\n",
    "# from newmodel import Generator, Discriminator, FeatureExtractor\n",
    "# from utilsnew import Visualizer2\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--dataset', type=str, default='cifar100', help='cifar10 | cifar100 | folder')\n",
    "parser.add_argument('--dataroot', type=str, default='./data', help='path to dataset')\n",
    "parser.add_argument('--workers', type=int, default=2, help='number of data loading workers')\n",
    "parser.add_argument('--batchSize', type=int, default=16, help='input batch size')\n",
    "parser.add_argument('--imageSize', type=int, default=100, help='the low resolution image size')\n",
    "parser.add_argument('--upSampling', type=int, default=2, help='low to high resolution scaling factor')\n",
    "parser.add_argument('--nEpochs', type=int, default=100, help='number of epochs to train for')\n",
    "parser.add_argument('--gEpochs', type=int, default=5, help='number of epochs to pre-train the generator for')\n",
    "parser.add_argument('--lrG', type=float, default=0.00001, help='learning rate for generator')\n",
    "parser.add_argument('--lrD', type=float, default=0.0000001, help='learning rate for discriminator')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--nGPU', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--netG', type=str, default='', help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netD', type=str, default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--out', type=str, default='checkpoints', help='folder to output model checkpoints')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "print(opt)\n",
    "\n",
    "try:\n",
    "    os.makedirs(opt.out)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((opt.imageSize*opt.upSampling,opt.imageSize*opt.upSampling)), \n",
    "                                transforms.ToTensor()]) #opt.upSampling\n",
    "\n",
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                std = [0.229, 0.224, 0.225])\n",
    "\n",
    "scale = transforms.Compose([transforms.ToPILImage(),\n",
    "                            transforms.Resize(opt.imageSize),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                                std = [0.229, 0.224, 0.225])\n",
    "                            ])\n",
    "\n",
    "\n",
    "backtrans= transforms.Compose([transforms.Normalize(mean = [-2.118, -2.036, -1.804], #Equivalent to un-normalizing ImageNet (for correct visualization)\n",
    "                            std = [4.367, 4.464, 4.444]),\n",
    "                            transforms.ToPILImage(),\n",
    "                            transforms.Resize(opt.imageSize)])\n",
    "\n",
    "dataset = datasets.ImageFolder(root= os.path.join(opt.dataroot, 'fake') ,\n",
    "                                transform=transform)\n",
    "datasetreal = datasets.ImageFolder(root= os.path.join(opt.dataroot, 'real') ,\n",
    "                                transform=transform)\n",
    "# assert dataset\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n",
    "\n",
    "\n",
    "dataloaderreal = torch.utils.data.DataLoader(datasetreal, batch_size=opt.batchSize,\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n",
    "\n",
    "netG = Generator(16, opt.upSampling) #6\n",
    "#netG.apply(weights_init)\n",
    "if opt.netG != '':\n",
    "    netG.load_state_dict(torch.load(opt.netG))\n",
    "print netG\n",
    "\n",
    "netD = Discriminator()\n",
    "#netD.apply(weights_init)\n",
    "if opt.netD != '':\n",
    "    netD.load_state_dict(torch.load(opt.netD))\n",
    "print netD\n",
    "\n",
    "# For the content loss\n",
    "feature_extractor = FeatureExtractor(torchvision.models.vgg19(pretrained=True))\n",
    "print feature_extractor\n",
    "content_criterion = nn.MSELoss()\n",
    "adversarial_criterion = nn.BCELoss()\n",
    "\n",
    "target_real = Variable(torch.ones(opt.batchSize,1))\n",
    "target_fake = Variable(torch.zeros(opt.batchSize,1))\n",
    "\n",
    "# if gpu is to be used\n",
    "if opt.cuda:\n",
    "    netG.cuda()\n",
    "    netD.cuda()\n",
    "    feature_extractor.cuda()\n",
    "    content_criterion.cuda()\n",
    "    adversarial_criterion.cuda()\n",
    "    target_real = target_real.cuda()\n",
    "    target_fake = target_fake.cuda()\n",
    "\n",
    "optimG = optim.Adam(netG.parameters(), lr=opt.lrG)\n",
    "optimD = optim.SGD(netD.parameters(), lr=opt.lrD, momentum=0.9, nesterov=True)\n",
    "\n",
    "configure('logs/' + 'genimage-' + str(opt.out) + str(opt.batchSize) + '-' + str(opt.lrG) + '-' + str(opt.lrD), flush_secs=5)\n",
    "visualizer = Visualizer2()\n",
    "dire ='resultimages/' +str(opt.out) +'/'\n",
    "if not os.path.exists(dire):\n",
    "    os.makedirs(dire)\n",
    "\n",
    "inputsG = torch.FloatTensor(opt.batchSize, 3, opt.imageSize, opt.imageSize)\n",
    "\n",
    "inputsGreal = torch.FloatTensor(opt.batchSize, 3, opt.imageSize*opt.upSampling, opt.imageSize*opt.upSampling)\n",
    "\n",
    "# Pre-train generator\n",
    "print 'Generator pre-training'\n",
    "for epoch in range(opt.gEpochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # Generate data\n",
    "        inputs, _ = data\n",
    "\n",
    "        # print(int(inputs.size()[0]) )\n",
    "        if not(int(inputs.size()[0]) == opt.batchSize):\n",
    "            continue\n",
    "        # print(inputs.size())\n",
    "        # Downsample images to low resolution\n",
    "        for j in range(opt.batchSize):\n",
    "            inputsG[j] = scale(inputs[j])\n",
    "            inputs[j] = normalize(inputs[j])\n",
    "\n",
    "        # Generate real and fake inputs\n",
    "        if opt.cuda:\n",
    "            inputsD_real = Variable(inputs.cuda())\n",
    "            inputsD_fake = netG(Variable(inputsG).cuda())\n",
    "        else:\n",
    "            inputsD_real = Variable(inputs)\n",
    "            inputsD_fake = netG(Variable(inputsG))\n",
    "\n",
    "\n",
    "        # imgplot = plt.imshow(backtrans(inputs[0]))\n",
    "        # plt.show()\n",
    "\n",
    "        ######### Train generator #########\n",
    "        netG.zero_grad()\n",
    "        # print(inputsD_fake.size())\n",
    "        # print(inputsD_real.size())\n",
    "\n",
    "        lossG_content = content_criterion(inputsD_fake, inputsD_real)\n",
    "        lossG_content.backward()\n",
    "\n",
    "        # Update generator weights\n",
    "        optimG.step()\n",
    "\n",
    "        if i%50==0:\n",
    "            # Status and display\n",
    "            print('[%d/%d][%d/%d] Loss_G: %.4f'\n",
    "                  % (epoch, opt.gEpochs, i, len(dataloader), lossG_content.data[0],))\n",
    "        # visualizer.show(inputsG, inputsD_real.cpu().data, inputsD_fake.cpu().data)\n",
    "\n",
    "    log_value('G_pixel_loss', lossG_content.data[0], epoch)\n",
    "    torch.save(netG.state_dict(), '%s/netG_pretrain_%d.pth' % (opt.out, epoch))\n",
    "\n",
    "\n",
    "print 'Adversarial training'\n",
    "lenreal = len(dataloaderreal)\n",
    "count=0\n",
    "visualcount=0\n",
    "realdata = iter(dataloaderreal)\n",
    "for epoch in range(opt.nEpochs):\n",
    "    mean_generator_content_loss = 0.0\n",
    "    mean_generator_adversarial_loss = 0.0\n",
    "    mean_generator_total_loss = 0.0\n",
    "    mean_discriminator_loss = 0.0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        ######### Train discriminator #########\n",
    "        netD.zero_grad()\n",
    "\n",
    "        # With real data\n",
    "   \n",
    "        if count==lenreal-1:\n",
    "            del realdata\n",
    "            del inputsreal\n",
    "            realdata = iter(dataloaderreal)\n",
    "        count= (count+1)%lenreal\n",
    "        inputsreal, _ = realdata.next()\n",
    "     \n",
    "        while not(int(inputsreal.size()[0]) == opt.batchSize):\n",
    "            inputsreal, _ = realdata.next()\n",
    "        for k in range(opt.batchSize):\n",
    "            inputsGreal[k] = normalize(inputsreal[k])\n",
    "\n",
    "        if opt.cuda:\n",
    "            inputsDreal = Variable(inputsGreal.cuda())\n",
    "        else:\n",
    "            inputsDreal = Variable(inputsGreal)\n",
    "\n",
    "        outputsre = netD(inputsDreal)\n",
    "        Dreal = outputsre.data.mean()\n",
    "        lossDreal = adversarial_criterion(outputsre, target_real)\n",
    "        # Update discriminator weights\n",
    "\n",
    "        # Generate data\n",
    "        inputs, _ = data\n",
    "\n",
    "        if not(int(inputs.size()[0]) == opt.batchSize):\n",
    "            continue\n",
    "\n",
    "        # Downsample images to low resolution\n",
    "        for j in range(opt.batchSize):\n",
    "            inputsG[j] = scale(inputs[j])\n",
    "            # print(inputs[j].size())\n",
    "            inputs[j] = normalize(inputs[j])\n",
    "\n",
    "        # Generate real and fake inputs\n",
    "        if opt.cuda:\n",
    "            inputsD_real = Variable(inputs.cuda())\n",
    "            inputsD_fake = netG(Variable(inputsG).cuda())\n",
    "        else:\n",
    "            inputsD_real = Variable(inputs)\n",
    "            inputsD_fake = netG(Variable(inputsG))\n",
    "          \n",
    "\n",
    "        # With fake data\n",
    "\n",
    "        outputs = netD(inputsD_real)\n",
    "        D_real = outputs.data.mean()\n",
    "\n",
    "        # lossD_real = adversarial_criterion(outputs, target_fake)\n",
    "        # lossD_real.backward()\n",
    "\n",
    "        outputsnew = netD(inputsD_fake.detach()) # Don't need to compute gradients wrt weights of netG (for efficiency)\n",
    "        D_fake = outputsnew.data.mean()\n",
    "\n",
    "        lossD = adversarial_criterion(outputsnew, target_fake) + 10*(adversarial_criterion(outputs, target_fake) + lossDreal)\n",
    "        mean_discriminator_loss+=lossD.data[0]\n",
    "        lossD.backward()\n",
    "\n",
    "        # Update discriminator weights\n",
    "        optimD.step()\n",
    "\n",
    "        ######### Train generator #########\n",
    "        netG.zero_grad()\n",
    "\n",
    "        real_features = Variable(feature_extractor(inputsD_real).data)\n",
    "        fake_features = feature_extractor(inputsD_fake)\n",
    "\n",
    "        lossG_content = content_criterion(fake_features, real_features)\n",
    "        lossG_adversarial = adversarial_criterion(netD(inputsD_fake), target_fake)\n",
    "        mean_generator_content_loss += lossG_content.data[0]\n",
    "\n",
    "        lossG_total = 0.1*lossG_content + lossG_adversarial \n",
    "        mean_generator_adversarial_loss += lossG_adversarial.data[0]\n",
    "        \n",
    "        mean_generator_total_loss += lossG_total.data[0]\n",
    "        lossG_total.backward()\n",
    "\n",
    "        # Update generator weights\n",
    "        optimG.step()\n",
    "        if i%50==0:\n",
    "            # Status and display\n",
    "            print('[%d/%d][%d/%d] Loss_Dreal: %.4f D(x): %.4f '% (epoch, opt.nEpochs, i, len(dataloader), lossDreal.data[0],Dreal))\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G (Content/Advers): %.4f/%.4f D(x): %.4f D(G(z)): %.4f'\n",
    "                  % (epoch, opt.nEpochs, i, len(dataloader),\n",
    "                     lossD.data[0], lossG_content.data[0], lossG_adversarial.data[0], D_real, D_fake,))\n",
    "        if i%200==0:\n",
    "            visualcount = visualizer.show(inputsG, inputsD_fake.cpu().data,visualcount,str(opt.out))\n",
    "    log_value('D_real_loss', lossDreal.data[0], epoch)\n",
    "    log_value('G_content_loss', mean_generator_content_loss/len(dataloader), epoch)\n",
    "    log_value('G_advers_loss', mean_generator_adversarial_loss/len(dataloader), epoch)\n",
    "    log_value('generator_total_loss', mean_generator_total_loss/len(dataloader), epoch)\n",
    "    log_value('D_advers_loss', mean_discriminator_loss/len(dataloader), epoch)\n",
    "\n",
    "    # Do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.out, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.out, epoch))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
